{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dbf026f-8d8c-4a44-b8cc-0d5208f4ef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "import json\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8020ba11-64f2-49de-b04a-56c7d16da07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE = 1\n",
    "NEGATIVE = 0\n",
    "ABSTAIN = -1\n",
    "\n",
    "@labeling_function()\n",
    "def llava_7b(image_name):\n",
    "    root_path = '../prompting_framework/prompting_results/eurosat/interpreter/'\n",
    "    llava_7b_results = 'eurosat_llava7b.json'\n",
    "    path_to_llava_7b_results = os.path.join(root_path,llava_7b_results)\n",
    "    with open(path_to_llava_7b_results, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data.get(image_name, -1)\n",
    "\n",
    "@labeling_function()\n",
    "def llava_13b(image_name):\n",
    "    root_path = '../prompting_framework/prompting_results/eurosat/interpreter'\n",
    "    llava_7b_results = 'eurosat_llava13b.json'\n",
    "    path_to_llava_7b_results = os.path.join(root_path,llava_7b_results)\n",
    "    with open(path_to_llava_7b_results, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data.get(image_name, -1)\n",
    "\n",
    "@labeling_function()\n",
    "def bakllava(image_name):\n",
    "    root_path = '../prompting_framework/prompting_results/eurosat/interpreter'\n",
    "    llava_7b_results = 'eurosat_bakllava.json'\n",
    "    path_to_llava_7b_results = os.path.join(root_path,llava_7b_results)\n",
    "    with open(path_to_llava_7b_results, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data.get(image_name, -1)\n",
    "\n",
    "@labeling_function()\n",
    "def llava_llama3(image_name):\n",
    "    root_path = '../prompting_framework/prompting_results/eurosat/interpreter'\n",
    "    llava_7b_results = 'eurosat_llava_llama3.json'\n",
    "    path_to_llava_7b_results = os.path.join(root_path,llava_7b_results)\n",
    "    with open(path_to_llava_7b_results, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data.get(image_name, -1)\n",
    "\n",
    "@labeling_function()\n",
    "def llava_phi3(image_name):\n",
    "    root_path = '../prompting_framework/prompting_results/eurosat/interpreter'\n",
    "    llava_7b_results = 'eurosat_llava_phi3.json'\n",
    "    path_to_llava_7b_results = os.path.join(root_path,llava_7b_results)\n",
    "    with open(path_to_llava_7b_results, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data.get(image_name, -1)\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def moondream(image_name):\n",
    "    root_path = '../prompting_framework/prompting_results/eurosat/interpreter'\n",
    "    llava_7b_results = 'eurosat_moondream.json'\n",
    "    path_to_llava_7b_results = os.path.join(root_path,llava_7b_results)\n",
    "    with open(path_to_llava_7b_results, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data.get(image_name, -1)\n",
    "\n",
    "@labeling_function()\n",
    "def llava_34b(image_name):\n",
    "    root_path = '../prompting_framework/prompting_results/eurosat/interpreter'\n",
    "    llava_7b_results = 'eurosat_llava34b.json'\n",
    "    path_to_llava_7b_results = os.path.join(root_path,llava_7b_results)\n",
    "    with open(path_to_llava_7b_results, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data.get(image_name, -1)\n",
    "\n",
    "@labeling_function()\n",
    "def minicpm(image_name):\n",
    "    root_path = '../prompting_framework/prompting_results/eurosat/interpreter'\n",
    "    llava_7b_results = 'eurosat_minicpm.json'\n",
    "    path_to_llava_7b_results = os.path.join(root_path,llava_7b_results)\n",
    "    with open(path_to_llava_7b_results, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data.get(image_name, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1772f5f3-ee27-419b-8166-84193c2dab32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13500 images in the Train set.\n",
      "There are 8100 images in the dev set.\n",
      "There are 8100 labels in the dev set.\n"
     ]
    }
   ],
   "source": [
    "train_data_json_path = '../prompting_framework/prompting_results/eurosat/interpreter/train_gt.json'\n",
    "dev_data_json_path = '../prompting_framework/prompting_results/eurosat/interpreter/test_gt.json'\n",
    "\n",
    "with open(train_data_json_path, 'r') as file:\n",
    "    train_data = json.load(file)\n",
    "\n",
    "# Extract and pad image names, ensuring they are 5 digits long before the '.png'\n",
    "train_image_names = []\n",
    "for item in train_data:\n",
    "    train_image_names.append(item)\n",
    "\n",
    "with open(dev_data_json_path, 'r') as file:\n",
    "    dev_data = json.load(file)\n",
    "    \n",
    "dev_image_names = []\n",
    "Y_dev = []\n",
    "for item in dev_data:\n",
    "    Y_dev.append(dev_data[item])\n",
    "    dev_image_names.append(item)\n",
    "\n",
    "print(f\"There are {len(train_image_names)} images in the Train set.\")\n",
    "print(f\"There are {len(dev_image_names)} images in the dev set.\")\n",
    "print(f\"There are {len(Y_dev)} labels in the dev set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eedf586-d080-49bf-9a1c-add7d319ab42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bakllava(train_image_names[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f282ea1-9844-4098-a5ca-e198c19c1fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import LFApplier\n",
    "\n",
    "list_of_all_the_models = ['llava_34b',\n",
    "       'llava_13b',\n",
    "       'llava_phi3',\n",
    "       'llava_7b',\n",
    "       'llava_llama3',\n",
    "       'minicpm',\n",
    "       'bakllava'\n",
    "       ]\n",
    "\n",
    "lfs = [llava_34b,\n",
    "       llava_13b,\n",
    "       llava_phi3,\n",
    "       llava_7b,\n",
    "       llava_llama3,\n",
    "       minicpm,\n",
    "       bakllava\n",
    "       ]\n",
    "\n",
    "applier = LFApplier(lfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02ae513d-a2ef-4141-95b2-878cb6309e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8100it [01:58, 68.17it/s]\n",
      "13500it [03:20, 67.50it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "\n",
    "L_dev = applier.apply(dev_image_names)\n",
    "L_train = applier.apply(train_image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64a8e827-5d9b-4b19-a12e-78d06c7344db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>llava_34b</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</td>\n",
       "      <td>0.901481</td>\n",
       "      <td>0.901358</td>\n",
       "      <td>0.765679</td>\n",
       "      <td>4462</td>\n",
       "      <td>2840</td>\n",
       "      <td>0.611065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llava_13b</th>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</td>\n",
       "      <td>0.915062</td>\n",
       "      <td>0.914938</td>\n",
       "      <td>0.765309</td>\n",
       "      <td>4360</td>\n",
       "      <td>3052</td>\n",
       "      <td>0.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llava_phi3</th>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</td>\n",
       "      <td>0.340988</td>\n",
       "      <td>0.337654</td>\n",
       "      <td>0.280247</td>\n",
       "      <td>1085</td>\n",
       "      <td>1677</td>\n",
       "      <td>0.392831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llava_7b</th>\n",
       "      <td>3</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</td>\n",
       "      <td>0.973704</td>\n",
       "      <td>0.965679</td>\n",
       "      <td>0.814444</td>\n",
       "      <td>4367</td>\n",
       "      <td>3520</td>\n",
       "      <td>0.553696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llava_llama3</th>\n",
       "      <td>4</td>\n",
       "      <td>[1, 3, 4, 5, 6, 7, 8, 9]</td>\n",
       "      <td>0.908025</td>\n",
       "      <td>0.905185</td>\n",
       "      <td>0.756667</td>\n",
       "      <td>3016</td>\n",
       "      <td>4339</td>\n",
       "      <td>0.410061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minicpm</th>\n",
       "      <td>5</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</td>\n",
       "      <td>0.772222</td>\n",
       "      <td>0.768272</td>\n",
       "      <td>0.645802</td>\n",
       "      <td>2414</td>\n",
       "      <td>3841</td>\n",
       "      <td>0.385931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bakllava</th>\n",
       "      <td>6</td>\n",
       "      <td>[1, 3, 4, 5, 6, 7, 8, 9]</td>\n",
       "      <td>0.187654</td>\n",
       "      <td>0.186914</td>\n",
       "      <td>0.174568</td>\n",
       "      <td>935</td>\n",
       "      <td>585</td>\n",
       "      <td>0.615132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              j                        Polarity  Coverage  Overlaps  \\\n",
       "llava_34b     0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  0.901481  0.901358   \n",
       "llava_13b     1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  0.915062  0.914938   \n",
       "llava_phi3    2  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  0.340988  0.337654   \n",
       "llava_7b      3  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  0.973704  0.965679   \n",
       "llava_llama3  4        [1, 3, 4, 5, 6, 7, 8, 9]  0.908025  0.905185   \n",
       "minicpm       5  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  0.772222  0.768272   \n",
       "bakllava      6        [1, 3, 4, 5, 6, 7, 8, 9]  0.187654  0.186914   \n",
       "\n",
       "              Conflicts  Correct  Incorrect  Emp. Acc.  \n",
       "llava_34b      0.765679     4462       2840   0.611065  \n",
       "llava_13b      0.765309     4360       3052   0.588235  \n",
       "llava_phi3     0.280247     1085       1677   0.392831  \n",
       "llava_7b       0.814444     4367       3520   0.553696  \n",
       "llava_llama3   0.756667     3016       4339   0.410061  \n",
       "minicpm        0.645802     2414       3841   0.385931  \n",
       "bakllava       0.174568      935        585   0.615132  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_dev = np.array(Y_dev)\n",
    "LFAnalysis(L_dev, lfs).lf_summary(Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fc01a19-55e8-4c54-9ae3-0aaf35c13bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, abstain_class=-1):\n",
    "    # Filter out samples where prediction is -1\n",
    "    valid_indices = y_pred != abstain_class\n",
    "    y_true_filtered = y_true[valid_indices]\n",
    "    y_pred_filtered = y_pred[valid_indices]\n",
    "\n",
    "    # Compute metrics\n",
    "    precision = precision_score(y_true_filtered, y_pred_filtered, average='macro')\n",
    "    recall = recall_score(y_true_filtered, y_pred_filtered, average='macro')\n",
    "    f1 = f1_score(y_true_filtered, y_pred_filtered, average='macro')\n",
    "    accuracy = accuracy_score(y_true_filtered, y_pred_filtered)\n",
    "\n",
    "    return {\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Accuracy': accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f6988d4-c2f2-44a1-8640-4719ce95c8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/macula/SMATousi/.conda/envs/snorkel/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/macula/SMATousi/.conda/envs/snorkel/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llava_34b</td>\n",
       "      <td>0.636037</td>\n",
       "      <td>0.642638</td>\n",
       "      <td>0.611065</td>\n",
       "      <td>0.594943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llava_13b</td>\n",
       "      <td>0.574568</td>\n",
       "      <td>0.705909</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.556386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llava_phi3</td>\n",
       "      <td>0.322776</td>\n",
       "      <td>0.452704</td>\n",
       "      <td>0.392831</td>\n",
       "      <td>0.267953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llava_7b</td>\n",
       "      <td>0.562570</td>\n",
       "      <td>0.623810</td>\n",
       "      <td>0.553696</td>\n",
       "      <td>0.508367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llava_llama3</td>\n",
       "      <td>0.410576</td>\n",
       "      <td>0.557944</td>\n",
       "      <td>0.410061</td>\n",
       "      <td>0.349638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>minicpm</td>\n",
       "      <td>0.395461</td>\n",
       "      <td>0.536678</td>\n",
       "      <td>0.385931</td>\n",
       "      <td>0.329697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bakllava</td>\n",
       "      <td>0.613103</td>\n",
       "      <td>0.486576</td>\n",
       "      <td>0.615132</td>\n",
       "      <td>0.510729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model    Recall  Precision  Accuracy  F1 Score\n",
       "0     llava_34b  0.636037   0.642638  0.611065  0.594943\n",
       "1     llava_13b  0.574568   0.705909  0.588235  0.556386\n",
       "2    llava_phi3  0.322776   0.452704  0.392831  0.267953\n",
       "3      llava_7b  0.562570   0.623810  0.553696  0.508367\n",
       "4  llava_llama3  0.410576   0.557944  0.410061  0.349638\n",
       "5       minicpm  0.395461   0.536678  0.385931  0.329697\n",
       "6      bakllava  0.613103   0.486576  0.615132  0.510729"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, accuracy_score, f1_score\n",
    "\n",
    "# Example ground truth and predictions for six models\n",
    "# Replace these arrays with actual predictions from each model\n",
    "y_true = Y_dev\n",
    "predictions = {}\n",
    "\n",
    "for i in range(L_dev.shape[1]):\n",
    "    predictions[list_of_all_the_models[i]] = L_dev[:,i]\n",
    "    \n",
    "# Create a DataFrame to store confusion matrix results and metrics\n",
    "confusion_data = []\n",
    "\n",
    "for model_name, y_pred in predictions.items():\n",
    "    \n",
    "    y_pred = np.array(y_pred)\n",
    "    # Confusion Matrix\n",
    "    metrics = calculate_metrics(Y_dev, y_pred)\n",
    "\n",
    "    precision = metrics['Precision']\n",
    "    recall = metrics['Recall']\n",
    "    f1 = metrics['F1 Score']\n",
    "    accuracy = metrics['Accuracy']\n",
    "    # Append data\n",
    "    confusion_data.append([\n",
    "        model_name,\n",
    "        recall, precision, accuracy, f1\n",
    "    ])\n",
    "\n",
    "# Convert to a DataFrame for display\n",
    "confusion_df = pd.DataFrame(confusion_data, columns=[\n",
    "    'Model', \n",
    "    'Recall', 'Precision', 'Accuracy', 'F1 Score'\n",
    "])\n",
    "\n",
    "# Display the table with confusion matrix and metrics\n",
    "confusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bd74e98-336c-426c-b2ac-f8215eb4e649",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:02<00:00, 2234.34epoch/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "label_model = LabelModel(cardinality=10, verbose=False)\n",
    "label_model.fit(L_train, Y_dev, n_epochs=5000, log_freq=500, seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2959b2b8-c793-4db3-aed7-d3b9629cf645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6121511260118815\n",
      "Recall: 0.6347555555555555\n",
      "F1 Score: 0.6080876216368022\n",
      "Accuracy: 0.6227160493827161\n"
     ]
    }
   ],
   "source": [
    "from snorkel.analysis import metric_score\n",
    "from snorkel.utils import probs_to_preds\n",
    "\n",
    "probs_dev = label_model.predict_proba(L_dev)\n",
    "preds_dev = probs_to_preds(probs_dev)\n",
    "\n",
    "metrics = calculate_metrics(Y_dev, preds_dev)\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c3c293-e4a1-4eea-acf8-738c3457a0fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e98515-e473-4622-9404-6931f76a19be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e87f3a1-57c3-4cfb-9865-2e36437275c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ffbb884-4f4a-457f-983a-dc7e39df9adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Custom dataset class for loading images\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_names, root_dir, labels, target_dists, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_names (list): List of image file names.\n",
    "            root_dir (string): Directory where images are stored.\n",
    "            transform (callable, optional): Optional transform to be applied on an image.\n",
    "        \"\"\"\n",
    "        self.image_names = image_names\n",
    "        self.root_dir = root_dir\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.target_dists = target_dists\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Build the full path of the image file\n",
    "        img_name = os.path.join(self.root_dir, self.image_names[idx])\n",
    "        label = self.labels[idx]\n",
    "        target_dist = self.target_dists[idx]\n",
    "        image = Image.open(img_name).convert('RGB')  # Load image as RGB\n",
    "\n",
    "        # Apply any transformations (e.g., resize, normalization)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label), torch.tensor(target_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "293e0c33-e38e-438b-9149-59877eae3730",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/home1/pupil/goowfd/CVPR_2025/Eurosat_all_images/\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        # transforms.Resize((224, 224)),  # Resize images to 224x224 (example)\n",
    "        transforms.ToTensor(),          # Convert images to PyTorch tensors\n",
    "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet mean/std\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ccaa017-29c2-49cb-b7ec-62854aa08aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_train = label_model.predict_proba(L_train)\n",
    "label_model_predictions = probs_to_preds(probs_train)\n",
    "\n",
    "probs_dev = label_model.predict_proba(L_dev)\n",
    "preds_dev = probs_to_preds(probs_dev)\n",
    "\n",
    "dataset = ImageDataset(image_names=train_image_names, \n",
    "                       root_dir=root_dir, \n",
    "                       labels=label_model_predictions, \n",
    "                       target_dists=probs_train, \n",
    "                       transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=4)\n",
    "\n",
    "dev_dataset = ImageDataset(image_names=dev_image_names, \n",
    "                           root_dir=root_dir, \n",
    "                           labels=Y_dev, \n",
    "                           target_dists=probs_dev, \n",
    "                           transform=transform)\n",
    "dev_dataloader = DataLoader(dev_dataset, batch_size=8, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2761beb-390b-4e9d-9e62-e49cdd600171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def expected_cross_entropy_loss(logits, target_distributions):\n",
    "    \"\"\"\n",
    "    Computes the expected cross-entropy loss for a batch of predictions and target distributions.\n",
    "\n",
    "    Parameters:\n",
    "    logits (torch.Tensor): The raw output from the model of shape (batch_size, num_classes).\n",
    "    target_distributions (torch.Tensor): The target class distributions of shape (batch_size, num_classes),\n",
    "                                         where each row is a probability distribution over classes.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: The expected cross-entropy loss.\n",
    "    \"\"\"\n",
    "    # Convert logits to log probabilities\n",
    "    log_probs = F.log_softmax(logits, dim=1)\n",
    "    \n",
    "    # Compute the element-wise product between target distributions and log probabilities\n",
    "    # Then, sum across classes to get the cross-entropy for each instance\n",
    "    cross_entropy = -torch.sum(target_distributions * log_probs, dim=1)\n",
    "    \n",
    "    # Take the mean over the batch\n",
    "    loss = cross_entropy.mean()\n",
    "    \n",
    "    return loss\n",
    "\n",
    "class MLPHead(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MLPHead, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Pretrained ResNet with MLP head for binary classification\n",
    "class ResNetWithMLP(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(ResNetWithMLP, self).__init__()\n",
    "        # Load a pretrained ResNet (e.g., ResNet18)\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "        \n",
    "        # Freeze the ResNet layers if you don't want to train them\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Replace the last fully connected layer with a custom MLP head\n",
    "        num_features = self.resnet.fc.in_features  # Get the number of features in the last layer\n",
    "        self.resnet.fc = MLPHead(input_dim=num_features, output_dim=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3d0bfc-75b2-4822-92fa-1abd82bbe7c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a3fc615-3eb4-4545-8a1b-89ee17503dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# Function to evaluate the model on the dev set\n",
    "def evaluate(model, dev_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for images, labels, target_dist in tqdm(dev_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass to get outputs\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Get predictions (class with the highest score)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            # Store true labels and predictions\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    return np.array(all_labels), np.array(all_preds)\n",
    "    \n",
    "def train(model, train_loader, dev_dataloader, criterion, optimizer, device, epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels, target_dist in tqdm(train_loader):\n",
    "            images, labels, target_dist = images.to(device), labels.to(device), target_dist.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Clear the gradients\n",
    "\n",
    "            outputs = model(images)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute the loss\n",
    "            # loss = expected_cross_entropy_loss(outputs, target_dist)\n",
    "\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Update the weights\n",
    "\n",
    "            # Calculate running loss and accuracy\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        accuracy = 100 * correct / total\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "        labels, predictions = evaluate(model, dev_dataloader, device)\n",
    "\n",
    "        # Calculate and print precision, recall, and F1-score\n",
    "        # calculate_metrics(labels, predictions)\n",
    "        metrics = calculate_metrics(labels, predictions)\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f933662-57cd-4885-964e-9e0fb6d7894d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/macula/SMATousi/.conda/envs/snorkel/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/macula/SMATousi/.conda/envs/snorkel/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1688/1688 [00:04<00:00, 403.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.4496, Accuracy: 53.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1013/1013 [00:02<00:00, 416.48it/s]\n",
      "/home/macula/SMATousi/.conda/envs/snorkel/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5651341224411505\n",
      "Recall: 0.593\n",
      "F1 Score: 0.5445835120790815\n",
      "Accuracy: 0.5861728395061728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1688/1688 [00:03<00:00, 511.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 1.0765, Accuracy: 66.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1013/1013 [00:01<00:00, 640.24it/s]\n",
      "/home/macula/SMATousi/.conda/envs/snorkel/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5890772181074071\n",
      "Recall: 0.6395666666666666\n",
      "F1 Score: 0.5992593076192259\n",
      "Accuracy: 0.6323456790123457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1688/1688 [00:03<00:00, 506.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 0.9559, Accuracy: 69.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1013/1013 [00:01<00:00, 675.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6279744046545459\n",
      "Recall: 0.6523333333333333\n",
      "F1 Score: 0.6197289121113572\n",
      "Accuracy: 0.6445679012345679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1688/1688 [00:03<00:00, 505.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Loss: 0.8732, Accuracy: 71.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1013/1013 [00:01<00:00, 675.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6105198108922545\n",
      "Recall: 0.6300555555555556\n",
      "F1 Score: 0.5960827777268908\n",
      "Accuracy: 0.6239506172839506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1688/1688 [00:03<00:00, 517.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss: 0.7897, Accuracy: 74.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1013/1013 [00:01<00:00, 659.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5897961929438174\n",
      "Recall: 0.6210666666666667\n",
      "F1 Score: 0.569075608337457\n",
      "Accuracy: 0.6112345679012345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1688/1688 [00:03<00:00, 505.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 0.7035, Accuracy: 76.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1013/1013 [00:01<00:00, 666.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6415826471689821\n",
      "Recall: 0.6199\n",
      "F1 Score: 0.5694372166137667\n",
      "Accuracy: 0.6117283950617284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1688/1688 [00:03<00:00, 516.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 0.6024, Accuracy: 80.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1013/1013 [00:01<00:00, 674.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5937664940295486\n",
      "Recall: 0.6168666666666667\n",
      "F1 Score: 0.5721025465384904\n",
      "Accuracy: 0.6075308641975309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1688/1688 [00:03<00:00, 512.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Loss: 0.5041, Accuracy: 84.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1013/1013 [00:01<00:00, 665.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5862892475171526\n",
      "Recall: 0.6243000000000001\n",
      "F1 Score: 0.5811612457511395\n",
      "Accuracy: 0.6160493827160494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1688/1688 [00:03<00:00, 511.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Loss: 0.4022, Accuracy: 87.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1013/1013 [00:01<00:00, 651.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5945692084777094\n",
      "Recall: 0.6199888888888888\n",
      "F1 Score: 0.5884762827321808\n",
      "Accuracy: 0.6148148148148148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1688/1688 [00:03<00:00, 527.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.3142, Accuracy: 90.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1013/1013 [00:01<00:00, 682.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6000585279012728\n",
      "Recall: 0.6104222222222223\n",
      "F1 Score: 0.5827996859532754\n",
      "Accuracy: 0.6038271604938271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = ResNetWithMLP(num_classes=10)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Binary classification loss\n",
    "optimizer = optim.Adam(model.resnet.fc.parameters(), lr=0.0001)  # Only optimize the MLP parameters\n",
    "\n",
    "# Train the model\n",
    "epochs = 10\n",
    "train(model, dataloader, dev_dataloader, criterion, optimizer, device, epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "49c24a77-3b66-462c-afbc-29f00b91b2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7c46449a-efc9-4a80-b016-13a1843ab7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 7, 9, 5, 7, 2, 3, 5])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label, dist = next(train_iter)\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e9936817-12ca-4323-b2bd-fe815c2f6b95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096efc18-2b0e-47c5-b127-4c82017e5be0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
