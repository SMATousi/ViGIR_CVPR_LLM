{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eda5a3a-7f01-45d5-9837-a9cc1fb6c08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "import json\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34c16916-e4b6-4174-9f9e-91621a79e940",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE = 1\n",
    "NEGATIVE = 0\n",
    "ABSTAIN = -1\n",
    "\n",
    "@labeling_function()\n",
    "def llava_7b(image_name):\n",
    "    root_path = '../prompting_framework/prompting_results/oxford/interpreter/'\n",
    "    llava_7b_results = 'oxford_llava7b.json'\n",
    "    path_to_llava_7b_results = os.path.join(root_path,llava_7b_results)\n",
    "    with open(path_to_llava_7b_results, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data.get(image_name, -1)\n",
    "\n",
    "@labeling_function()\n",
    "def llava_13b(image_name):\n",
    "    root_path = '../prompting_framework/prompting_results/oxford/interpreter'\n",
    "    llava_7b_results = 'oxford_llava13b.json'\n",
    "    path_to_llava_7b_results = os.path.join(root_path,llava_7b_results)\n",
    "    with open(path_to_llava_7b_results, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data.get(image_name, -1)\n",
    "\n",
    "@labeling_function()\n",
    "def bakllava(image_name):\n",
    "    root_path = '../prompting_framework/prompting_results/oxford/interpreter'\n",
    "    llava_7b_results = 'oxford_bakllava.json'\n",
    "    path_to_llava_7b_results = os.path.join(root_path,llava_7b_results)\n",
    "    with open(path_to_llava_7b_results, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data.get(image_name, -1)\n",
    "\n",
    "@labeling_function()\n",
    "def llava_llama3(image_name):\n",
    "    root_path = '../prompting_framework/prompting_results/oxford/interpreter'\n",
    "    llava_7b_results = 'oxford_llava_llama3.json'\n",
    "    path_to_llava_7b_results = os.path.join(root_path,llava_7b_results)\n",
    "    with open(path_to_llava_7b_results, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data.get(image_name, -1)\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def minicpm(image_name):\n",
    "    root_path = '../prompting_framework/prompting_results/oxford/interpreter'\n",
    "    llava_7b_results = 'oxford_minicpm.json'\n",
    "    path_to_llava_7b_results = os.path.join(root_path,llava_7b_results)\n",
    "    with open(path_to_llava_7b_results, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data.get(image_name, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af74caaa-bff0-4697-ba55-b7f5773e8b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2944 images in the Train set.\n",
      "There are 3669 images in the dev set.\n",
      "There are 3669 labels in the dev set.\n"
     ]
    }
   ],
   "source": [
    "train_data_json_path = '../prompting_framework/prompting_results/oxford/interpreter/train_gt.json'\n",
    "dev_data_json_path = '../prompting_framework/prompting_results/oxford/interpreter/test_gt.json'\n",
    "\n",
    "with open(train_data_json_path, 'r') as file:\n",
    "    train_data = json.load(file)\n",
    "\n",
    "# Extract and pad image names, ensuring they are 5 digits long before the '.png'\n",
    "train_image_names = []\n",
    "for item in train_data:\n",
    "    train_image_names.append(item)\n",
    "\n",
    "with open(dev_data_json_path, 'r') as file:\n",
    "    dev_data = json.load(file)\n",
    "    \n",
    "dev_image_names = []\n",
    "Y_dev = []\n",
    "for item in dev_data:\n",
    "    Y_dev.append(dev_data[item])\n",
    "    dev_image_names.append(item)\n",
    "\n",
    "print(f\"There are {len(train_image_names)} images in the Train set.\")\n",
    "print(f\"There are {len(dev_image_names)} images in the dev set.\")\n",
    "print(f\"There are {len(Y_dev)} labels in the dev set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5037fe75-4b86-4288-bfcd-e1dbc831f470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bakllava(train_image_names[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d818c860-98a2-4261-ae96-b78da0b298a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import LFApplier\n",
    "\n",
    "list_of_all_the_models = ['llava_13b',\n",
    "       'llava_7b',\n",
    "       'llava_llama3',\n",
    "       'minicpm',\n",
    "       'bakllava'\n",
    "       ]\n",
    "\n",
    "lfs = [llava_13b,\n",
    "       llava_7b,\n",
    "       llava_llama3,\n",
    "       minicpm,\n",
    "       bakllava\n",
    "       ]\n",
    "\n",
    "applier = LFApplier(lfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ab5745f-eeca-405d-bd4d-71e68a783bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3669it [00:04, 741.06it/s]\n",
      "2944it [00:03, 742.40it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "\n",
    "L_dev = applier.apply(dev_image_names)\n",
    "L_train = applier.apply(train_image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41857227-bb88-4a63-8b93-344aaaa7e6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>llava_13b</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 4, 5, 6, 7, 8, 10, 16, 18, 23, 24, 25, 26,...</td>\n",
       "      <td>0.403107</td>\n",
       "      <td>0.376124</td>\n",
       "      <td>0.179613</td>\n",
       "      <td>788</td>\n",
       "      <td>691</td>\n",
       "      <td>0.532792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llava_7b</th>\n",
       "      <td>1</td>\n",
       "      <td>[0, 4, 5, 8, 10, 22, 23, 24, 25, 26, 29, 32, 33]</td>\n",
       "      <td>0.467157</td>\n",
       "      <td>0.415372</td>\n",
       "      <td>0.195149</td>\n",
       "      <td>868</td>\n",
       "      <td>846</td>\n",
       "      <td>0.506418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llava_llama3</th>\n",
       "      <td>2</td>\n",
       "      <td>[0, 4, 5, 10, 16, 23, 24, 25, 29, 32]</td>\n",
       "      <td>0.235759</td>\n",
       "      <td>0.213137</td>\n",
       "      <td>0.105478</td>\n",
       "      <td>406</td>\n",
       "      <td>459</td>\n",
       "      <td>0.469364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minicpm</th>\n",
       "      <td>3</td>\n",
       "      <td>[0, 4, 5, 6, 7, 8, 10, 16, 18, 19, 22, 23, 24,...</td>\n",
       "      <td>0.463069</td>\n",
       "      <td>0.380758</td>\n",
       "      <td>0.180703</td>\n",
       "      <td>1319</td>\n",
       "      <td>380</td>\n",
       "      <td>0.776339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bakllava</th>\n",
       "      <td>4</td>\n",
       "      <td>[0, 4, 6, 10, 23, 24, 25, 32, 33]</td>\n",
       "      <td>0.107386</td>\n",
       "      <td>0.102480</td>\n",
       "      <td>0.054511</td>\n",
       "      <td>224</td>\n",
       "      <td>170</td>\n",
       "      <td>0.568528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              j                                           Polarity  Coverage  \\\n",
       "llava_13b     0  [0, 4, 5, 6, 7, 8, 10, 16, 18, 23, 24, 25, 26,...  0.403107   \n",
       "llava_7b      1   [0, 4, 5, 8, 10, 22, 23, 24, 25, 26, 29, 32, 33]  0.467157   \n",
       "llava_llama3  2              [0, 4, 5, 10, 16, 23, 24, 25, 29, 32]  0.235759   \n",
       "minicpm       3  [0, 4, 5, 6, 7, 8, 10, 16, 18, 19, 22, 23, 24,...  0.463069   \n",
       "bakllava      4                  [0, 4, 6, 10, 23, 24, 25, 32, 33]  0.107386   \n",
       "\n",
       "              Overlaps  Conflicts  Correct  Incorrect  Emp. Acc.  \n",
       "llava_13b     0.376124   0.179613      788        691   0.532792  \n",
       "llava_7b      0.415372   0.195149      868        846   0.506418  \n",
       "llava_llama3  0.213137   0.105478      406        459   0.469364  \n",
       "minicpm       0.380758   0.180703     1319        380   0.776339  \n",
       "bakllava      0.102480   0.054511      224        170   0.568528  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_dev = np.array(Y_dev)\n",
    "LFAnalysis(L_dev, lfs).lf_summary(Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22d494a9-eb7e-4eb0-b802-49c6a7b1c476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, abstain_class=-1):\n",
    "    # Filter out samples where prediction is -1\n",
    "    valid_indices = y_pred != abstain_class\n",
    "    y_true_filtered = y_true[valid_indices]\n",
    "    y_pred_filtered = y_pred[valid_indices]\n",
    "\n",
    "    # Compute metrics\n",
    "    precision = precision_score(y_true_filtered, y_pred_filtered, average='macro')\n",
    "    recall = recall_score(y_true_filtered, y_pred_filtered, average='macro')\n",
    "    f1 = f1_score(y_true_filtered, y_pred_filtered, average='macro')\n",
    "    accuracy = accuracy_score(y_true_filtered, y_pred_filtered)\n",
    "\n",
    "    return {\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Accuracy': accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b4d5f5a-1ebd-4bc4-a44c-1f7bf743c6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/macula/SMATousi/.conda/envs/snorkel/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/macula/SMATousi/.conda/envs/snorkel/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/macula/SMATousi/.conda/envs/snorkel/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/macula/SMATousi/.conda/envs/snorkel/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/macula/SMATousi/.conda/envs/snorkel/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/macula/SMATousi/.conda/envs/snorkel/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llava_13b</td>\n",
       "      <td>0.354265</td>\n",
       "      <td>0.318590</td>\n",
       "      <td>0.532792</td>\n",
       "      <td>0.279984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llava_7b</td>\n",
       "      <td>0.324740</td>\n",
       "      <td>0.220103</td>\n",
       "      <td>0.506418</td>\n",
       "      <td>0.245728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llava_llama3</td>\n",
       "      <td>0.237491</td>\n",
       "      <td>0.200568</td>\n",
       "      <td>0.469364</td>\n",
       "      <td>0.202906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>minicpm</td>\n",
       "      <td>0.505769</td>\n",
       "      <td>0.489446</td>\n",
       "      <td>0.776339</td>\n",
       "      <td>0.479285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bakllava</td>\n",
       "      <td>0.295730</td>\n",
       "      <td>0.331590</td>\n",
       "      <td>0.568528</td>\n",
       "      <td>0.254197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model    Recall  Precision  Accuracy  F1 Score\n",
       "0     llava_13b  0.354265   0.318590  0.532792  0.279984\n",
       "1      llava_7b  0.324740   0.220103  0.506418  0.245728\n",
       "2  llava_llama3  0.237491   0.200568  0.469364  0.202906\n",
       "3       minicpm  0.505769   0.489446  0.776339  0.479285\n",
       "4      bakllava  0.295730   0.331590  0.568528  0.254197"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, accuracy_score, f1_score\n",
    "\n",
    "# Example ground truth and predictions for six models\n",
    "# Replace these arrays with actual predictions from each model\n",
    "y_true = Y_dev\n",
    "predictions = {}\n",
    "\n",
    "for i in range(L_dev.shape[1]):\n",
    "    predictions[list_of_all_the_models[i]] = L_dev[:,i]\n",
    "    \n",
    "# Create a DataFrame to store confusion matrix results and metrics\n",
    "confusion_data = []\n",
    "\n",
    "for model_name, y_pred in predictions.items():\n",
    "    \n",
    "    y_pred = np.array(y_pred)\n",
    "    # Confusion Matrix\n",
    "    metrics = calculate_metrics(Y_dev, y_pred)\n",
    "\n",
    "    precision = metrics['Precision']\n",
    "    recall = metrics['Recall']\n",
    "    f1 = metrics['F1 Score']\n",
    "    accuracy = metrics['Accuracy']\n",
    "    # Append data\n",
    "    confusion_data.append([\n",
    "        model_name,\n",
    "        recall, precision, accuracy, f1\n",
    "    ])\n",
    "\n",
    "# Convert to a DataFrame for display\n",
    "confusion_df = pd.DataFrame(confusion_data, columns=[\n",
    "    'Model', \n",
    "    'Recall', 'Precision', 'Accuracy', 'F1 Score'\n",
    "])\n",
    "\n",
    "# Display the table with confusion matrix and metrics\n",
    "confusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b48f62f-15be-4e92-8cd3-201e580a4970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:03<00:00, 1458.79epoch/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "label_model = LabelModel(cardinality=37, verbose=False)\n",
    "label_model.fit(L_train, Y_dev, n_epochs=5000, log_freq=500, seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f458df8-87df-45c9-8602-98f858d0f947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.23611091617721394\n",
      "Recall: 0.34430663502092074\n",
      "F1 Score: 0.25272754650139534\n",
      "Accuracy: 0.34614336331425455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/macula/SMATousi/.conda/envs/snorkel/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from snorkel.analysis import metric_score\n",
    "from snorkel.utils import probs_to_preds\n",
    "\n",
    "probs_dev = label_model.predict_proba(L_dev)\n",
    "preds_dev = probs_to_preds(probs_dev)\n",
    "\n",
    "metrics = calculate_metrics(Y_dev, preds_dev)\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0d9ce1-ddfc-4c44-bf39-f3e3aca15e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b96b347-5587-459a-a7e4-67da9b82b3c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
