{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dcf9e5d-519b-4a16-a462-aabd46ce3641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import argparse\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import sys\n",
    "from PIL import Image\n",
    "from transformers import AutoTokenizer, CLIPTextModel, CLIPTokenizer, CLIPModel \n",
    "from torch.nn.functional import cosine_similarity\n",
    "import torch\n",
    "import signal\n",
    "import torch.nn.functional as F\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84d133a0-4cf5-4bfb-9e15-028a8a44dd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores(class_embeddings, query_embedding, prompts, temperature=0.8):\n",
    "    scores = []\n",
    "    # Compute cosine similarity scores\n",
    "    for class_name in class_embeddings:\n",
    "        similarity_scores = cosine_similarity(torch.tensor(query_embedding), torch.tensor(class_embeddings[class_name]), dim=1)  # Shape: [37]\n",
    "        similarity_scores = similarity_scores / temperature\n",
    "        scores.append(similarity_scores.item())\n",
    "\n",
    "    # probabilities = F.softmax(similarity_scores, dim=0)\n",
    "    # Find the highest matching score and corresponding item\n",
    "\n",
    "    max_prob_index = torch.argmax(torch.tensor(scores)).item()\n",
    "    max_prob = scores[max_prob_index]\n",
    "    best_match = prompts[max_prob_index]\n",
    "    \n",
    "    # Print the result\n",
    "   # print(f\"Best match: {best_match} with a similarity score of {max_score:.4f}\")\n",
    "    return best_match, scores, max_prob\n",
    "\n",
    "def generate_context_embedding(class_names, model_name, options):\n",
    "    prompt = \"You are working on a difficult fine-grained image classification task, here are the only classes you can choose from\"+class_names\n",
    "    context_response = ollama.generate(model=model_name, prompt=prompt, options=options)\n",
    "    return context_response['context']\n",
    "\n",
    "def compute_class_embeddings(class_names_list, model_name) :\n",
    "    class_embeddings = {}\n",
    "    print(\"Computing the class embeddings --\")\n",
    "    for class_name in tqdm(class_names_list) :\n",
    "        # print(class_name)\n",
    "        response = ollama.embed(model=model_name, input=class_name)\n",
    "        class_embeddings[class_name] = response[\"embeddings\"]\n",
    "    \n",
    "    return class_embeddings\n",
    "\n",
    "class TimeoutException(Exception):\n",
    "    pass\n",
    "\n",
    "def timeout_handler(signum, frame):\n",
    "    raise TimeoutException\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f771c2e3-359a-415f-87ab-0a1d5109ad21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling Ollama Model...\n",
      "bakllava\n",
      "Done Pulling..\n"
     ]
    }
   ],
   "source": [
    "class_names = \"Speed limit (20km/h), Speed limit (30km/h), Speed limit (50km/h), Speed limit (60km/h), Speed limit (70km/h), Speed limit (80km/h), End of speed limit (80km/h), Speed limit (100km/h), Speed limit (120km/h), No passing, No passing for vehicles over 3.5 metric tons, Right-of-way at the next intersection, Priority road, Yield, Stop, No vehicles, Vehicles over 3.5 metric tons prohibited, No entry, General caution, Dangerous curve to the left, Dangerous curve to the right, Double curve, Bumpy road, Slippery road, Road narrows on the right, Road work, Traffic signals, Pedestrians, Children crossing, Bicycles crossing, Beware of ice/snow, Wild animals crossing, End of all speed and passing limits, Turn right ahead, Turn left ahead, Ahead only, Go straight or right, Go straight or left, Keep right, Keep left, Roundabout mandatory, End of no passing, End of no passing by vehicles over 3.5 metric tons\"\n",
    "\n",
    "data = {}\n",
    "base_dir = '/home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/'\n",
    "data_samples_file_path = \"/home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/annotations/traffic_signs_train.json\"\n",
    "data_path = '/home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images' #args.data_path\n",
    "images_dir = '/home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/' # /root/home/data/traffic/images/ -- need train/0/\n",
    "\n",
    "with open(data_samples_file_path, 'r') as file:\n",
    "    raw_data = json.load(file)\n",
    "\n",
    "for image_path, details in raw_data.items():\n",
    "    class_id = details[\"class_id\"]\n",
    "    class_name = details[\"class_name\"]\n",
    "    image_file_path = image_path.lower()\n",
    "    \n",
    "    data[os.path.join(images_dir, image_file_path)] = {\"label\" : class_id, \"class\" : class_name}\n",
    "\n",
    "model_name  = 'bakllava'\n",
    "results_dir = '/home/macula/SMATousi/CVPR/results-test/'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "dataset_name = \"traffic\"\n",
    "subset = 'train'\n",
    "results_file_name=os.path.join(results_dir,f\"{dataset_name}-{model_name}-{subset}.json\")\n",
    "raw_image_info=os.path.join(results_dir,f\"{dataset_name}-{model_name}-{subset}-raw_info.json\")\n",
    "print(\"Pulling Ollama Model...\")\n",
    "print(model_name)\n",
    "ollama.pull(model_name)\n",
    "print(\"Done Pulling..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2bd0b54-6c61-49a5-ad87-97f7a9199543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the class embeddings --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 43/43 [00:02<00:00, 18.87it/s]\n"
     ]
    }
   ],
   "source": [
    "timeout_duration = 20\n",
    "\n",
    "options= {  # new\n",
    "        \"seed\": 123,\n",
    "        \"temperature\": 0,\n",
    "        \"num_ctx\": 2048, # must be set, otherwise slightly random output\n",
    "    }\n",
    "\n",
    "# model_id_clip  = \"openai/clip-vit-large-patch14\"\n",
    "# device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# print(\"Setting up CLIP..\")\n",
    "\n",
    "# tokenizer = CLIPTokenizer.from_pretrained(model_id_clip)\n",
    "# text_encoder = CLIPTextModel.from_pretrained(model_id_clip).to(device)\n",
    "# clip_model = CLIPModel.from_pretrained(model_id_clip).to(device)\n",
    "\n",
    "class_names_list = [name.strip() for name in class_names.split(',')]\n",
    "class_dict = {class_name : i for i, class_name in enumerate(class_names_list)}\n",
    "# ollama.pull(\"mxbai-embed-large\") # model for embedding class names text\n",
    "class_embeddings = compute_class_embeddings(class_names_list, model_name)\n",
    "#traffic_embeedings = get_class_embeddings(class_names_list, tokenizer, text_encoder)\n",
    "context_embedding = generate_context_embedding(class_names, model_name, options)\n",
    "# print(\"Done setting up clip...\")\n",
    "model_labels = {}\n",
    "prompt = \"Identify the traffic sign. Choose one from the list\"\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d743a71c-0eee-4041-8b68-4659d8c0a938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00589415, -0.00210187,  0.00154161, ..., -0.00469216,\n",
       "         0.0100439 , -0.0070477 ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(class_embeddings['Speed limit (30km/h)']) - np.array(class_embeddings['Speed limit (20km/h)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5b13abee-78b1-4843-8741-6df35dc55eaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00000_00010.png'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b038d36-4179-4eb9-9adc-f11ea1047c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 6/39209 [00:17<29:23:01,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00000_00005.png took longer than 20 seconds. Moving to the next one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 9/39209 [00:25<31:51:47,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00000_00008.png took longer than 20 seconds. Moving to the next one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                      | 10/39209 [00:27<26:48:49,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00000_00009.png took longer than 20 seconds. Moving to the next one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                      | 12/39209 [00:28<15:21:28,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00000_00010.png took longer than 20 seconds. Moving to the next one.\n",
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00000_00011.png took longer than 20 seconds. Moving to the next one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                      | 13/39209 [00:28<11:06:04,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00000_00012.png took longer than 20 seconds. Moving to the next one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                      | 18/39209 [00:50<35:39:32,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00000_00017.png took longer than 20 seconds. Moving to the next one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                      | 21/39209 [01:01<32:30:45,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00000_00019.png took longer than 20 seconds. Moving to the next one.\n",
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00000_00020.png took longer than 20 seconds. Moving to the next one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                      | 23/39209 [01:01<16:44:28,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00000_00021.png took longer than 20 seconds. Moving to the next one.\n",
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00000_00022.png took longer than 20 seconds. Moving to the next one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 25/39209 [01:02<8:57:45,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00000_00023.png took longer than 20 seconds. Moving to the next one.\n",
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00000_00024.png took longer than 20 seconds. Moving to the next one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 27/39209 [01:02<5:20:45,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00000_00025.png took longer than 20 seconds. Moving to the next one.\n",
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00000_00026.png took longer than 20 seconds. Moving to the next one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 30/39209 [01:02<2:52:39,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00000_00027.png took longer than 20 seconds. Moving to the next one.\n",
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00000_00028.png took longer than 20 seconds. Moving to the next one.\n",
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00000_00029.png took longer than 20 seconds. Moving to the next one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 32/39209 [01:02<2:08:42,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00001_00000.png took longer than 20 seconds. Moving to the next one.\n",
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00001_00001.png took longer than 20 seconds. Moving to the next one.\n",
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00001_00002.png took longer than 20 seconds. Moving to the next one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 34/39209 [01:03<1:39:26,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00001_00003.png took longer than 20 seconds. Moving to the next one.\n",
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00001_00004.png took longer than 20 seconds. Moving to the next one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 36/39209 [01:03<1:32:43,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00001_00005.png took longer than 20 seconds. Moving to the next one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 37/39209 [01:03<1:58:06,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00001_00006.png took longer than 20 seconds. Moving to the next one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 39/39209 [01:07<8:45:21,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00001_00007.png took longer than 20 seconds. Moving to the next one.\n",
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00001_00008.png took longer than 20 seconds. Moving to the next one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 41/39209 [01:07<5:20:10,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00001_00009.png took longer than 20 seconds. Moving to the next one.\n",
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00001_00010.png took longer than 20 seconds. Moving to the next one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 43/39209 [01:08<3:25:15,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00001_00011.png took longer than 20 seconds. Moving to the next one.\n",
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00001_00012.png took longer than 20 seconds. Moving to the next one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 45/39209 [01:08<2:27:19,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00001_00013.png took longer than 20 seconds. Moving to the next one.\n",
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00001_00014.png took longer than 20 seconds. Moving to the next one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 46/39209 [01:08<2:08:29,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00001_00015.png took longer than 20 seconds. Moving to the next one.\n",
      "Prompt for /home/macula/SMATousi/cluster/docker-images/ollama/image_datasets/traffic/images/train/20/00020_00001_00016.png took longer than 20 seconds. Moving to the next one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                                     | 54/39209 [01:42<37:03:16,  3.41s/it]"
     ]
    }
   ],
   "source": [
    "for key,info in tqdm(data.items()):\n",
    "    # print(type(key))\n",
    "    count = count + 1\n",
    "    image_path = key\n",
    "\n",
    "#disp_img(image_path)\n",
    "\n",
    "    signal.signal(signal.SIGALRM, timeout_handler)\n",
    "    signal.alarm(timeout_duration)\n",
    "\n",
    "    try:\n",
    "        \n",
    "        response = ollama.generate(model=model_name, prompt=prompt, images=[image_path], options=options, context=context_embedding)\n",
    "        # response = ollama.generate(model=model_name, prompt=prompt, options=options, context=context_embedding)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "        model_response = response['response']\n",
    "        query_response = ollama.embed(model=model_name, input=model_response)\n",
    "        query_embedding = query_response[\"embeddings\"]\n",
    "        # print(query_embedding)\n",
    "    \n",
    "        best_match, probs, max_prob = compute_scores(class_embeddings, query_embedding[0], class_names_list, temperature=0.2)\n",
    "        class_label = class_dict[best_match]\n",
    "    \n",
    "        # Initialize variables for the best match\n",
    "        # best_match = None\n",
    "        # best_similarity = -1  # Cosine similarity ranges from -1 to 1, so start with a very low value\n",
    "        \n",
    "        # # Find the best matching embedding\n",
    "        # for class_name, class_embedding in class_embeddings.items():\n",
    "        #     similarity = 1 - cosine(query_embedding[0], class_embedding[0])  # Cosine similarity is 1 - cosine distance\n",
    "        #     if similarity > best_similarity:\n",
    "        #         best_similarity = similarity\n",
    "        #         best_match = class_name\n",
    "        # #= get_query_embedding(model_response, tokenizer, text_encoder)\n",
    "        # matched_label = best_match #compute_scores(traffic_embeedings, response_embedding, class_names_list)\n",
    "        \n",
    "       # print(f\"{image_path} | {matched_label} | {model_response}\")\n",
    "        model_labels[image_path] = {\n",
    "            \"label\": class_label, # integer index representing class\n",
    "            \"class\": best_match, # string indicating class name\n",
    "            \"model_response\": model_response # string coming from the model\n",
    "        }\n",
    "        # break\n",
    "    except:\n",
    "        print(f\"Prompt for {image_path} took longer than {timeout_duration} seconds. Moving to the next one.\")\n",
    "        model_labels[image_path] = {\n",
    "            \"label\": None, # integer index representing class\n",
    "            \"class\": None, # string indicating class name\n",
    "            \"model_response\": None # string coming from the model\n",
    "        }\n",
    "\n",
    "    finally:\n",
    "        signal.alarm(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34413279-b23b-4495-b756-e553e60a832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4235f265-4bb0-4b63-9e7e-5189a649d3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "temperature = 0.2\n",
    "# Compute cosine similarity scores\n",
    "for class_name in class_embeddings:\n",
    "    similarity_scores = cosine_similarity(torch.tensor(query_embedding[0]), torch.tensor(class_embeddings[class_name]), dim=1)  # Shape: [37]\n",
    "    similarity_scores = similarity_scores / temperature\n",
    "    scores.append(similarity_scores.item())\n",
    "\n",
    "probabilities = F.softmax(torch.tensor(scores), dim=0)\n",
    "# # Find the highest matching score and corresponding item\n",
    "\n",
    "max_prob_index = torch.argmax(probabilities).item()\n",
    "max_prob = probabilities[max_prob_index]\n",
    "best_match = class_names_list[max_prob_index]\n",
    "\n",
    "# Print the result\n",
    "# print(f\"Best match: {best_match} with a similarity score of {max_score:.4f}\")\n",
    "# return best_match, probabilities, max_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "372c234c-6790-431e-b50d-250797a8fea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0372, 0.0369, 0.0391, 0.0368, 0.0415, 0.0405, 0.0235, 0.0433, 0.0393,\n",
       "        0.0127, 0.0259, 0.0244, 0.0114, 0.0118, 0.0114, 0.0159, 0.0254, 0.0153,\n",
       "        0.0216, 0.0296, 0.0295, 0.0139, 0.0157, 0.0170, 0.0266, 0.0145, 0.0175,\n",
       "        0.0156, 0.0124, 0.0124, 0.0123, 0.0107, 0.0303, 0.0273, 0.0294, 0.0209,\n",
       "        0.0213, 0.0211, 0.0206, 0.0233, 0.0200, 0.0169, 0.0271])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "48637eab-bdcf-493b-80e9-d45926713e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c156c751-14cd-43e6-bff0-6fc59f9718d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Speed limit (100km/h)'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0f0478-ed0d-4020-8af5-1e59774e3044",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
